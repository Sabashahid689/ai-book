from typing import List, Dict, Any
from utils.rag.prompt_engineering import rag_prompt_engineer
from utils.qdrant_client import qdrant_manager


class ResponseValidationService:
    """
    Service to validate that chatbot answers are sourced only from textbook content.
    """
    
    @staticmethod
    def validate_response_sources(answer: str, sources: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Validate that the answer is properly sourced from the provided sources.
        
        Args:
            answer: The answer provided by the chatbot
            sources: List of sources used to generate the answer
            
        Returns:
            Validation results with confidence scores
        """
        # Check if the answer references information that appears in the sources
        answer_lower = answer.lower()
        
        # Extract content from sources
        source_contents = []
        for source in sources:
            # For this implementation, we'll check if the answer contains terms from the sources
            if "content_id" in source:
                # In a real implementation, we would retrieve the actual content 
                # associated with the content_id to validate against
                source_contents.append(source["content_id"])
        
        # Perform validation using our prompt engineering utility
        if sources:
            # Get the first source's content for validation (simplified approach)
            # In a real implementation, we would retrieve the actual content of all sources
            context = " ".join([source.get("title", "") for source in sources])
            validation_result = rag_prompt_engineer.validate_response_against_context(
                answer, context
            )
        else:
            # If no sources provided, the answer cannot be validated
            validation_result = {
                "is_valid": False,
                "overlap_ratio": 0,
                "contains_hallucination_indicator": False,
                "is_generic": True,
                "confidence": 0.0,
                "error": "No sources provided for validation"
            }
        
        return validation_result
    
    @staticmethod
    def validate_content_extraction(question: str, retrieved_chunks: List[Dict], 
                                  generated_answer: str) -> Dict[str, Any]:
        """
        Validate that the generated answer is properly extracted from retrieved content.
        
        Args:
            question: Original question asked
            retrieved_chunks: Chunks retrieved from vector store
            generated_answer: Answer generated by the model
            
        Returns:
            Detailed validation report
        """
        # Combine all retrieved content
        all_retrieved_content = " ".join([chunk.get("chunk_text", "") for chunk in retrieved_chunks])
        
        # Validate the answer against retrieved content
        validation_result = rag_prompt_engineer.validate_response_against_context(
            generated_answer, all_retrieved_content
        )
        
        # Additional checks
        result_details = {
            "is_valid": validation_result["is_valid"],
            "confidence": validation_result["confidence"],
            "overlap_ratio": validation_result["overlap_ratio"],
            "content_fidelity": len(set(generated_answer.lower().split()) & 
                                   set(all_retrieved_content.lower().split())) / 
                               max(len(set(all_retrieved_content.lower().split())), 1),
            "sources_used": len(retrieved_chunks),
            "answer_length": len(generated_answer),
            "content_length": len(all_retrieved_content),
        }
        
        return result_details


# Create a singleton instance
response_validation_service = ResponseValidationService()